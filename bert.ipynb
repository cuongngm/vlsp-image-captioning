{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53296354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from vncorenlp import VnCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6428e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5070eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdrsegmenter = VnCoreNLP(\"tachtu/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8747ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Tin nhanh Việt Nam là một trang báo điện tử tại Việt Nam được thành lập bởi tập đoàn FPT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9363d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Tin',\n",
       "  'nhanh',\n",
       "  'Việt_Nam',\n",
       "  'là',\n",
       "  'một',\n",
       "  'trang',\n",
       "  'báo_điện_tử',\n",
       "  'tại',\n",
       "  'Việt_Nam',\n",
       "  'được',\n",
       "  'thành_lập',\n",
       "  'bởi',\n",
       "  'tập_đoàn',\n",
       "  'FPT']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = rdrsegmenter.tokenize(text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c27d5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tin nhanh Việt_Nam là một trang báo_điện_tử tại Việt_Nam được thành_lập bởi tập_đoàn FPT'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_token = ' '.join([' '.join(sent) for sent in sents])\n",
    "text_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd2eb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f45bca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [650, 650, 973, 52, 486, 322, 15, 585, 3159, 2, 1, 1, 1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "638717f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nhân_viên',\n",
       " 'nhân_viên',\n",
       " 'y_tế',\n",
       " 'đang',\n",
       " 'tiến_hành',\n",
       " 'làm_việc',\n",
       " 'với',\n",
       " 'mẫu',\n",
       " 'xét_nghiệm',\n",
       " '</s>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(test_ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa73a9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  1362,  1430,  1231,  7564,    52,  1287, 12425,     2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor([tokenizer.encode('nhân viên y tế đang cầm tăm')])\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9ee375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    features = model(input_ids)\n",
    "features['last_hidden_state'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d6f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ('Các nhân viên y tế đang cầm tăm bông xét nghiệm.', 'Các y tá đang đẩy xe lăn cho một phụ nữ lớn tuổi ở hành lang bệnh viện.', 'Bốn người đi bộ băng qua đường.', 'Các viên thuốc trong lòng bàn tay một người.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8b4d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 650, 973, 52, 1287, 12425, 2597, 3159, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 9, 8905, 52, 1172, 11940, 13, 16, 419, 5541, 25, 3967, 757, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1586, 18, 57, 215, 1731, 89, 109, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 9, 1430, 529, 12, 605, 3178, 16, 18, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "max_length = 30\n",
    "for sample in samples:\n",
    "    input_ids = [1] * max_length\n",
    "    sample = sample.lower()\n",
    "    sample = sample.translate(table)\n",
    "    sents = rdrsegmenter.tokenize(sample)\n",
    "    text_token = ' '.join([' '.join(sent) for sent in sents])\n",
    "    ids = tokenizer.encode(text_token)\n",
    "    input_ids[:len(ids)] = ids\n",
    "    print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a4fcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='vinai/phobert-base', vocab_size=64000, model_max_len=256, is_fast=False, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0fc2749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2]\n",
      "[0, 0, 2]\n",
      "[0, 3, 2]\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(tokenizer.eos_token))\n",
    "print(tokenizer.encode(tokenizer.bos_token))\n",
    "print(tokenizer.encode(tokenizer.unk_token))\n",
    "print(tokenizer.encode(tokenizer.pad_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee470b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4050,  0.0952,  0.6486,  ...,  0.9016,  0.4926,  0.8443],\n",
       "        [-0.2853, -2.4276,  0.2896,  ..., -0.4787,  1.1296,  0.8064],\n",
       "        [ 0.0398, -0.8494,  0.9300,  ..., -0.9980,  1.1040, -0.5601],\n",
       "        [-0.8764, -0.2059,  1.0152,  ..., -0.3907, -0.5555,  1.8224],\n",
       "        [ 0.1565,  1.0361, -0.7197,  ..., -1.6926, -0.6694, -0.2688]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "u = nn.Embedding(10, 768)\n",
    "out = u(zz)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2aad288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz = [1, 4, 6, 7, 9]\n",
    "zz = torch.LongTensor(zz)\n",
    "zz.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40582b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Các nhân viên y tế đang cầm tăm bông xét nghiệm. </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0, 146, 1362, 1430, 1231, 7564, 52, 1287, 12425, 2597, 1522, 37257, 21573, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef462feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[-1.1100, -1.1531, -1.3806,  ...,  1.0475, -1.4357, -0.0573],\n",
    "        [-1.5643,  1.7656,  0.1941,  ...,  0.1666, -0.8521,  1.8053],\n",
    "        [-0.6592, -1.3805,  1.7218,  ...,  1.3835,  0.5102,  0.3721],\n",
    "        [ 0.3386, -0.1872, -0.0580,  ...,  0.2153, -0.5882,  0.3987],\n",
    "        [ 0.3179,  0.4561,  0.9766,  ..., -1.5936,  1.3590, -0.6045]],"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
